# -*- coding: utf-8 -*-
"""Bigmart Sales.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T3QIhVFQQOhqszv3xg2JfLEYcFLnNFtx
"""

import numpy as np # linear algebra
import pandas as pd # data processing
import math
from matplotlib import pyplot as plt
import seaborn as sns

from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder, PolynomialFeatures, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.metrics import mean_absolute_error , mean_squared_error , r2_score
from xgboost import XGBRegressor

# load the data
df=pd.read_csv('https://raw.githubusercontent.com/JananiJayakumar23/Bigmart/refs/heads/main/train.csv')
df1=pd.read_csv('https://raw.githubusercontent.com/JananiJayakumar23/Bigmart/refs/heads/main/test.csv')

# to view the top 5 records in a dataset
df.head()

#to get the count of products in Item_Type
df.Item_Type.value_counts()

# to get the number of rows and columns i.e observations and columns
df.shape

# to get the info about data and datatype
df.info()

# to get the min,max,mean,td and descriptive stats
df.describe(include="all")

# to get the number of missing datapoints in a column
df.isnull().sum().sort_values(ascending=False)

df.Outlet_Establishment_Year

df['Outlet_Establishment_Year'].dtype

df['Outlet_Identifier'].value_counts()

# test dataframe
df1.head()

df1.shape

df1.info()

#EDA
numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()
numeric_cols

df.describe().T

_, ax = plt.subplots(nrows=1, ncols=5, figsize=(20, 3))

for index, col in enumerate(numeric_cols):
    sns.histplot(df[col], kde=False, ax=ax[index], color='pink')  # set pink color
    ax[index].set_title(f'{col} distribution')

plt.tight_layout()
plt.show()

_, ax = plt.subplots(nrows=1, ncols=5, figsize=(26, 4))

for index, col in enumerate(numeric_cols):
    sns.kdeplot(data=df, x=col, ax=ax[index], color='red')
    ax[index].set_title(f'{col} distribution in Train')

_, ax = plt.subplots(nrows=1, ncols=4, figsize=(26, 4))

for index, col in enumerate(['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']):
    sns.distplot(df1[col], kde=True, ax=ax[index], color='pink')
    ax[index].set_title(f'{col} distribution in Test')

_, ax = plt.subplots(nrows=1, ncols=5, figsize=(26,8))
for index, col in enumerate(numeric_cols):
    sns.boxplot(data=df, y=col, ax=ax[index],color='pink')
    ax[index].set_title(f'{col} distribution')

_, ax = plt.subplots(nrows=1, ncols=5, figsize=(26,8))
for index, col in enumerate(numeric_cols):
    sns.violinplot(data=df, y=col, ax=ax[index],color='pink',inner='quartile')
    ax[index].set_title(f'{col} distribution')

#categorical columns
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
categorical_cols

['Item_Identifier',
 'Item_Fat_Content',
 'Item_Type',
 'Outlet_Identifier',
 'Outlet_Size',
 'Outlet_Location_Type',
 'Outlet_Type']
categorical_cols_to_display = [
                                 'Item_Fat_Content',
                                 'Item_Type',
                                 'Outlet_Size',
                                 'Outlet_Location_Type',
                                 'Outlet_Type'
                                ]
for col in categorical_cols_to_display:
    print(f"Number of values in the {col} column is:\n{df[col].value_counts() }")
    print("--" * 30)

df['Outlet_Location_Type'].unique().tolist()

_, ax = plt.subplots(nrows=3, ncols=2, figsize=(32, 36))

for index, col in enumerate(categorical_cols_to_display):
    r = index // 2
    c = index % 2
    g = sns.countplot(data=df, x=col , ax=ax[r][c],color='pink', width=0.6)
    g.set_xticklabels(g.get_xticklabels(), rotation=45, ha="right", fontsize=18)
    ax[r][c].set_title(f'{col} distribution', fontsize=24)
    plt.tight_layout()

_, ax = plt.subplots(nrows=3, ncols=2, figsize=(16, 16))

for index, col in enumerate(categorical_cols_to_display):
    r = index // 2
    c = index % 2
    df[col].value_counts().plot(kind="pie", autopct="%.2f", ax=ax[r][c])
    #g.set_xticklabels(g.get_xticklabels(), rotation=45, ha="right", fontsize=18)
    #ax[r][c].set_title(f'{col} distribution', fontsize=24)
    plt.tight_layout()

"""Bivariate Analysis- Numerical"""

targetsales = "Item_Outlet_Sales"

_, ax = plt.subplots(nrows=1, ncols=3, figsize=(26, 4))

for index, col in enumerate(['Item_Weight', 'Item_Visibility', 'Item_MRP']):
    sns.scatterplot(data=df,x=col, y=targetsales, ax=ax[index], color='pink')
    #ax[index].set_title(f'{col} distribution')

_, ax = plt.subplots(nrows=1, ncols=3, figsize=(26, 4))

for index, col in enumerate(['Item_Weight', 'Item_Visibility', 'Item_MRP']):
    sns.scatterplot(data=df,x=col, y=targetsales, ax=ax[index], color='pink',hue='Outlet_Type')

sns.heatmap(df.corr(numeric_only=True), annot=True, cmap="coolwarm")

sns.barplot(data=df, x='Outlet_Size', y=targetsales,color='pink')

df.Outlet_Establishment_Year

"""imputer = KNNImputer(n_neighbors=5)
df = pd.DataFrame(imputer.fit_transform(df),columns = df.columns)

Missing value
"""

# for df
df['Outlet_Size'] = df.Outlet_Size.fillna(df.Outlet_Size.dropna().mode()[0]) #replace by the median after
df['Item_Weight'] = df.Item_Weight.fillna(df.Item_Weight.mean())

# for df1
df1['Outlet_Size'] = df1.Outlet_Size.fillna(df1.Outlet_Size.dropna().mode()[0]) #replace by the median after
df1['Item_Weight'] = df1.Item_Weight.fillna(df1.Item_Weight.mean())

"""Missing values"""

df.isnull().sum()

def detect_outliers(df, feature):
    Q1  = df[feature].quantile(0.25)
    Q3  = df[feature].quantile(0.75)
    IQR = Q3 - Q1

    upper_limit = Q3 + 1.5 * IQR
    lower_limit = Q1 - 1.5 * IQR
    return upper_limit, lower_limit

upper, lower = detect_outliers(df, "Item_Visibility")
print("Upper limit: ", upper)
print("Lower limit: ", lower)

_, ax = plt.subplots(nrows=1, ncols=2, figsize=(32, 6))
sns.boxplot(x=df['Item_Visibility'], ax=ax[0],color='pink')

# removing outliers using the above function
train = df[(df['Item_Visibility'] > lower) & (df['Item_Visibility'] < upper)] #train
test = df1[(df1['Item_Visibility'] > lower) & (df1['Item_Visibility'] < upper)]     #test

sns.boxplot(x=train['Item_Visibility'], ax=ax[1],color='pink')
plt.title('Item_Visibility Distribution before VS after removing outliers')
plt.show()

upper, lower = detect_outliers(df, "Item_Outlet_Sales")
print("Upper limit: ", upper)
print("Lower limit: ", lower)

_, ax = plt.subplots(nrows=1, ncols=2, figsize=(32, 6))
sns.boxplot(x=df['Item_Outlet_Sales'], ax=ax[0],color='pink')

# removing outliers using the same function
df = df[(df['Item_Outlet_Sales'] > lower) & (df['Item_Outlet_Sales'] < upper)]

sns.boxplot(x=df['Item_Outlet_Sales'], ax=ax[1],color='pink')
plt.title('Item Outlet Sales Distribution before VS after removing outliers')
plt.show()

df['Item_Fat_Content'] = df['Item_Fat_Content'].map({'Low Fat' :'Low Fat',
                                                           'low fat' :"Low Fat",
                                                           'LF'      :"Low Fat",
                                                           'Regular' :'Regular',
                                                           'reg'     :"Regular"
                                                          })

df1['Item_Fat_Content'] = df1['Item_Fat_Content'].map({'Low Fat' :'Low Fat',
                                                           'low fat' :"Low Fat",
                                                           'LF'      :"Low Fat",
                                                           'Regular' :'Regular',
                                                           'reg'     :"Regular"
                                                          })

sns.countplot(x=df['Item_Fat_Content'],color='pink');

df['Outlet_Age'] = 2023 - df['Outlet_Establishment_Year']
df1['Outlet_Age'] = 2023 - df1['Outlet_Establishment_Year']

del df['Outlet_Establishment_Year']
del df1['Outlet_Establishment_Year']

sns.countplot(x=df['Outlet_Age'],color='pink');

"""Label encoding"""

df['Outlet_Size'] = df['Outlet_Size'].map({'Small'  : 1,
                                                 'Medium' : 2,
                                                 'High'   : 3
                                                 }).astype(int)
df1['Outlet_Size'] = df1['Outlet_Size'].map({'Small'  : 1,
                                               'Medium' : 2,
                                               'High'   : 3
                                              }).astype(int)

sns.countplot(x=df['Outlet_Size'],color='pink');

df['Outlet_Location_Type'] = df['Outlet_Location_Type'].str[-1:].astype(int)
df1['Outlet_Location_Type']  = df1['Outlet_Location_Type'].str[-1:].astype(int)
sns.countplot(x=df['Outlet_Location_Type'],color='pink')

df['Item_Identifier_Categories'] = df['Item_Identifier'].str[0:2] #.astype(int)
df1['Item_Identifier_Categories']  = df1['Item_Identifier'].str[0:2]

sns.countplot(x=df['Item_Identifier_Categories'],color='pink')

df.head()

encoder = LabelEncoder()
ordinal_features = ['Item_Fat_Content', 'Outlet_Type', 'Outlet_Location_Type']

for feature in ordinal_features:
    df[feature] = encoder.fit_transform(df[feature])
    df1[feature]  = encoder.fit_transform(df1[feature])

df.shape

df1.shape

df.head()

"""One hot encoding"""

df = pd.get_dummies(df, columns=['Item_Type', 'Item_Identifier_Categories', 'Outlet_Identifier'], drop_first=True)
df1 = pd.get_dummies(df1,  columns=['Item_Type', 'Item_Identifier_Categories', 'Outlet_Identifier'], drop_first=True)

train.head()
train.shape

"""Data Preprocessing"""

df.drop(labels=['Item_Identifier'], axis=1, inplace=True)
df1.drop(labels=['Item_Identifier'],  axis=1, inplace=True)

X = df.drop('Item_Outlet_Sales', axis=1)
y = df['Item_Outlet_Sales']

X.head()

y.head()

"""Splitting into 80% training and 20% testing"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

"""1)Linear Regression Model"""

lin_reg_model = LinearRegression()
lin_reg_model.fit(X_train, y_train)

lin_reg_predictions = lin_reg_model.predict(X_test)

print('Training score  : {}'.format(lin_reg_model.score(X_train, y_train)))
print('Test score      : {}'.format(lin_reg_model.score(X_test, y_test)))

lin_reg_mse  = mean_squared_error(y_test , lin_reg_predictions)
lin_reg_rmse = math.sqrt(lin_reg_mse)
lin_reg_r2   = r2_score(y_test, lin_reg_predictions)

print('RMSE  \t         ----> {}'.format(lin_reg_rmse))
print('R2 Score         ----> {}'.format(lin_reg_r2))

steps = [
    ('scaler', StandardScaler()),
    ('poly',   PolynomialFeatures(degree=2)),
    ('model',  LinearRegression())
       ]

lin_reg_pipeline = Pipeline(steps)

lin_reg_pipeline.fit(X_train, y_train)

print('Training score  : {}'.format(lin_reg_pipeline.score(X_train, y_train)))
print('Test score      : {}'.format(lin_reg_pipeline.score(X_test, y_test)))

"""Regularised Linear Regression"""

steps = [
            ('scaler', StandardScaler()),
            ('poly'  , PolynomialFeatures(degree=2)),
            ('model' , Ridge(alpha=7, fit_intercept=True))
       ]

ridge_pipeline = Pipeline(steps)
ridge_pipeline.fit(X_train, y_train)

print('Training Score  : {}'.format(ridge_pipeline.score(X_train, y_train)))
print('Test Score      : {}'.format(ridge_pipeline.score(X_test, y_test)))

ridge_predictions = ridge_pipeline.predict(X_test)

ridge_mse  = mean_squared_error(y_test , ridge_predictions)
ridge_rmse = math.sqrt(ridge_mse)
ridge_r2   = r2_score(y_test, ridge_predictions)

print('Ridge RMSE  \t         ----> {}'.format(ridge_rmse))
print('Ridge R2 Score         ----> {}'.format(ridge_r2))

"""l1 Regularisation"""

steps = [
            ('scaler', StandardScaler()),
            ('poly', PolynomialFeatures(degree=2)),
            ('model', Lasso(alpha=0.2, fit_intercept=True))
        ]

lasso_pipeline = Pipeline(steps)

lasso_pipeline.fit(X_train, y_train)

print('Training score  : {}'    .format(lasso_pipeline.score(X_train, y_train)))
print('Test score      : {}'    .format(lasso_pipeline.score(X_test, y_test)))

lasso_predictions = lasso_pipeline.predict(X_test)

lasso_mse  = mean_squared_error(y_test , lasso_predictions)
lasso_rmse = math.sqrt(lasso_mse)
lasso_r2   = r2_score(y_test, lasso_predictions)
print("Accuracy --> ",lin_reg_model.score(X_test, y_test)*100)

print('Lasso RMSE  \t         ----> {}'.format(lasso_rmse))
print('Lasso R2 Score         ----> {}'.format(lasso_r2))

"""2)Random forest model"""

rand_forest_model = RandomForestRegressor()
rand_forest_model.fit(X_train, y_train)

rand_forest_predictions = rand_forest_model.predict(X_test)

print('Training score  : {}'.format(rand_forest_model.score(X_train, y_train)))
print('Test score      : {}'.format(rand_forest_model.score(X_test, y_test)))

rand_forest_mse = mean_squared_error(y_test , rand_forest_predictions)
rand_forest_rmse = math.sqrt(rand_forest_mse)
rand_forest_r2 = r2_score(y_test, rand_forest_predictions)
print("Accuracy --> ", rand_forest_model .score(X_test, y_test)*100)
print('RandomForest RMSE  \t       ----> {}'.format(rand_forest_rmse))
print('RandomForest R2 Score       ----> {}'.format(rand_forest_r2))

"""3) XG Boost"""

from xgboost import XGBRegressor

xgb_model = XGBRegressor(
    n_estimators=500,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

xgb_model.fit(X_train, y_train)

xgb_predictions = xgb_model.predict(X_test)
print('XGBoost Training score  : {}'.format(xgb_model.score(X_train, y_train)))
print('XGBoost Test score      : {}'.format(xgb_model.score(X_test, y_test)))

xgb_mse = mean_squared_error(y_test , xgb_predictions)
xgb_rmse = math.sqrt(xgb_mse)
xgb_r2 = r2_score(y_test, xgb_predictions)

print('XGBoost RMSE  \t   ----> {}'.format(xgb_rmse))
print('XGBoost R2 Score   ----> {}'.format(xgb_r2))

"""4)Gradient Boosting Regressor"""

#Train the model
from sklearn.ensemble import GradientBoostingRegressor
GBR = GradientBoostingRegressor(n_estimators=100, max_depth=4)
#Fit
GBR.fit(X_train, y_train)
print("Accuracy --> ", GBR.score(X_test, y_test)*100)

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 4, 5],
    'learning_rate': [0.05, 0.1, 0.2],
    'subsample': [0.8, 1.0]
}

gbr = GradientBoostingRegressor(random_state=42)
grid = GridSearchCV(gbr, param_grid, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)
grid.fit(X_train, y_train)
print("Best Parameters:", grid.best_params_)
print("Best Validation RMSE:", -grid.best_score_)

best_model = grid.best_estimator_
print("Test set R² (Accuracy): {:.2f}%".format(best_model.score(X_test, y_test) * 100))

import warnings
warnings.simplefilter("ignore")

import pickle

# set seed for reproductibility
np.random.seed(0)

# Saving model to pickle file
with open("BigMart_Sales_Prediction_Model.pkl", "wb") as file: # file is a variable for storing the newly created file.
    pickle.dump(lasso_pipeline, file)